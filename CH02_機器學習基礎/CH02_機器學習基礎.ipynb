{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章機器學習基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機器學習起源於上世紀50年代，1959 年在 IBM 工作的 Arthur Samuel 設計了一個下棋程式，這個程式具有學習的能力，它可以在不斷的對弈中提高自己。從而提出了「機器學習」這個 概念，它是一個結合了多個學科如機率論，優化理論，統計等，最終在電腦上實現自我獲取新知識，學習改善自己的這樣一個研究領域。機器學習是人工智能的一個子集，目前已經發展出許多有用的方法，某些支持向量機(SVM)，回歸(Regression)，決策樹，隨機森林，強化方法，集成學習，深度學習等等，一定程度上可以幫助人們完成一些數據預測，自動化，自動決策，最優化 等初步替代腦力的任務。本章我們主要介紹下機器學習的基本概念：監督學習、分類算法、邏輯回歸、代價函數、損失函數、LDA、PCA、決策樹、支持向量機、EM算法、聚類和降維以及模型評估有一些方法、指標等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1機器學習本質"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機器學習（Machine Learning，ML），顧名思義，讓機器去學習。這裡，機器指的是計算機，是算法運行的物理載體，你也可以把各種算法本身當做一個有輸入和輸出的機器。那麼 對於一個任務及其表現的變量方法，設計一種算法，讓算法能夠提取中數據所蘊含的規律，則叫機器學習。如果輸入機器的數據是帶有標籤的 ，就在於有有監督學習。如果數據是無標籤的，就是無監督學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 什麼是神經網絡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神經網絡就是按照一定規則將多個神經元連接起來的網絡。不同的神經網絡，具有不同的連接規則。例如全連接（Full Connected，FC）<br>\n",
    "神經網絡的規則包括：\n",
    "\n",
    "- 有三個層：輸入層，輸出層，隱藏層。\n",
    "- 同一層的神經元之間沒有連接。\n",
    "- 完全連接的含義：第 N 層的每個神經元和第 N-1 層的所有神經元相連，第 N-1 層神經元的輸出就是第 N 層神經元的輸入。\n",
    "- 每個連接都有一個權值。\n",
    "\n",
    "**神經網絡架構**\n",
    "圖 2-1 是一個神經網絡系統，它由很多層組成。對輸入信息的傳遞和加工處理。\n",
    "![圖2-2神經網絡系統](img/ch2/2.5.1.png)\n",
    "\n",
    "圖 2-1 神經網絡系統"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 各種常見算法圖示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用機器學習中，我們經常會遇見各種算法，圖 2-2 是各種常見算法的圖示。\n",
    "\n",
    "|線性回歸(Linear Regression)|K-平均算法 (k-means clustering)|正規化 (Regularization)|\n",
    "| :----------------------:| :----------------------:| :----------------------:|\n",
    "|![](./img/ch2/2.1/1.jpg)|![](./img/ch2/2.1/2.jpg)|![](./img/ch2/2.1/3.jpg)|\n",
    "\n",
    "|決策樹 (Decision Tree)|貝氏推論 (Bayesian inference)|Kernel-Based Learning Algorithm|\n",
    "| :----------------------:| :----------------------:| :----------------------:|\n",
    "| ![](./img/ch2/2.2.4.png)| ![](./img/ch2/2.1/5.jpg)| ![](./img/ch2/2.1/6.jpg)|\n",
    "\n",
    "|集群分析 (Cluster Analysis)|關聯規則學習 (Association rule learning)|神經網絡 (Neural Network)|\n",
    "| :----------------------:| :----------------------:| :-----------------------:|\n",
    "| ![](./img/ch2/2.1/7.jpg)| ![](./img/ch2/2.2.8.png)| ![](./img/ch2/2.2.09.png)|\n",
    "\n",
    "|深度學習 (Deep Learning)|主成分分析 (Principal Component Analysis)|集成學習 (Ensemble Learning)|\n",
    "| :-----------------------:| :-----------------------:| :-----------------------:|\n",
    "| ![](./img/ch2/2.2.10.png)| ![](./img/ch2/2.2.11.png)| ![](./img/ch2/2.2.12.png)|\n",
    "\n",
    "圖 2-2 各種常見算法圖示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Computational Graph 的導數計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational Graph 的導數計算是反向傳播，利用 Chain Rule 和隱函式 (Implicit Equation) 求導。\n",
    "\n",
    "假設 $z=f(u, v)$ 在點 $(u, v)$ 處偏導連續，$(u, v)$ 是關於 $t$ 的函數，在 $t$ 點可導，求 $z$ 在 $t$ 點的導數。\n",
    "\n",
    "根據Chain Rule有：\n",
    "$$\n",
    "\\frac {dz}{dt}=\\frac {\\partial z}{\\partial u}\\frac {du}{dt}+\\frac{\\partial z}{\\partial v}\\frac {dv}{dt}\n",
    "$$\n",
    "\n",
    "Example：\n",
    "$$\n",
    "f(x)= x^{2}\n",
    "$$\n",
    "$$\n",
    "g(x)=2x+1\n",
    "$$\n",
    "\n",
    "則：\n",
    "$$\n",
    "{f(g(x))}'=2(g(x))g'(x)=2(2x+1)2=8x+4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 局部最優解 與 全局最優解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笑談局部最優和最大化\n",
    "\n",
    ">柏拉圖有一天問老師蘇格拉底什麼是愛情？蘇格拉底叫他到麥田走一次，摘一顆最大的麥穗回來，不許回頭，只可摘一次。柏拉圖空著手出來了，他的理由是，看見不錯的，卻不知道是不是最好的，一次次僥倖，走到盡頭時，才發現還不如前面的，於是放棄。蘇格拉底告訴他：“這就是愛情。”這故事讓我們明白了一個道理，因為生命的一些不確定性，所以可能最優解是很難尋找到的，或者說根本就不存在，我們應該設置一些限定條件，然後在這個範圍內尋找最優解，也就是局部最優解-有所斬獲總比空手而歸強，哪怕這種斬獲只是一次有趣的經歷。\n",
    ">柏拉圖有一天又問什麼是婚姻？蘇格拉底叫他到樹林走一次，選一棵最好的樹做聖誕樹，也是不許回頭，只許選一次。看起來直挺，翠綠，卻有點稀疏的杉樹回來，他的理由是，有了上回的教訓，好不容易看見一棵看似不錯的，又發現時間，體力已經快不夠用了，也不管是不是最好的，就拿回來了。蘇格拉底告訴他：“這就是婚姻。”\n",
    "\n",
    "最佳問題解答一般有局部最優解和最大化最優解：\n",
    "- 局部最優解：在函數值空間的一個有限區域內尋找代替解答(最接近)。<br>\n",
    "- 最優解：是在函數值空間整個區域尋找問題的最佳解答。<br>\n",
    "- 函數局部最小點是它的函數值小於或等於附近點的點，但是有可能大於較遠距離的點。<br>\n",
    "- 全局最小點是那種它的函數值小於或等於所有的可行點。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 大數據與深度學習之間的關係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先來看大數據，機器學習及數據挖掘三者簡單的定義：\n",
    "\n",
    "**大數據**：通常被定義為「超過常用軟件工具捕獲，管理和處理能力」的數據集。<br>\n",
    "**機器學習**：關心問題是如何整合電腦程序使用經驗自動改進。<br>\n",
    "**數據挖掘**：是從數據中提取特定模式算法的應用，在數據挖掘中，重點在於算法的應用，而不是算法本身。<br>\n",
    "\n",
    "三者之間的關係如下：\n",
    "數據挖掘是一個過程，在此過程中機器學習算法被用來提取數據集中的潛在的潛在模式的工具。\n",
    "\n",
    "大數據與深度學習關係總結如下：\n",
    "- 深度學習是一種模擬大腦的行為。可以從所學習對象的機制以及行為等等很多相關聯的方面進行學習，模仿類型行為以及思維。<br>\n",
    "- 深度學習對於大數據技術開發的每一個階段幫助，無論是數據的分析還是挖掘還是建模，只有深度學習，這些工作才會有可能一一得到實現。<br>\n",
    "- 深度學習轉變了解決問題的思維。很多時候發現問題到解決問題，走一步算一步不再是主要的解決問題的方式。在深度學習的基礎上，要求我們從開始到最後都要依據一個目標，為了需要優化的那個最終目標去進行處理以及將數據放入到數據應用平台上去，這就是 End-to-End。<br>\n",
    "- 在大數據方面的深度學習都是從基礎的角度出發的，深度學習需要一個框架或者一個系統。總而言之，將大數據通過深度分析變為現實，這就是深度學習和大數據的最直接關係。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
