{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第二章機器學習基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機器學習起源於上世紀50年代，1959 年在 IBM 工作的 Arthur Samuel 設計了一個下棋程式，這個程式具有學習的能力，它可以在不斷的對弈中提高自己。從而提出了「機器學習」這個 概念，它是一個結合了多個學科如機率論，優化理論，統計等，最終在電腦上實現自我獲取新知識，學習改善自己的這樣一個研究領域。機器學習是人工智能的一個子集，目前已經發展出許多有用的方法，某些支持向量機(SVM)，回歸(Regression)，決策樹，隨機森林，強化方法，集成學習，深度學習等等，一定程度上可以幫助人們完成一些數據預測，自動化，自動決策，最優化 等初步替代腦力的任務。本章我們主要介紹下機器學習的基本概念：監督學習、分類算法、邏輯回歸、代價函數、損失函數、LDA、PCA、決策樹、支持向量機、EM算法、聚類和降維以及模型評估有一些方法、指標等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 基本概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1機器學習本質"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "機器學習（Machine Learning，ML），顧名思義，讓機器去學習。這裡，機器指的是計算機，是算法運行的物理載體，你也可以把各種算法本身當做一個有輸入和輸出的機器。那麼 對於一個任務及其表現的變量方法，設計一種算法，讓算法能夠提取中數據所蘊含的規律，則叫機器學習。如果輸入機器的數據是帶有標籤的 ，就在於有有監督學習。如果數據是無標籤的，就是無監督學習。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 什麼是神經網絡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神經網絡就是按照一定規則將多個神經元連接起來的網絡。不同的神經網絡，具有不同的連接規則。例如全連接（Full Connected，FC）<br>\n",
    "神經網絡的規則包括：\n",
    "\n",
    "- 有三個層：輸入層，輸出層，隱藏層。\n",
    "- 同一層的神經元之間沒有連接。\n",
    "- 完全連接的含義：第 N 層的每個神經元和第 N-1 層的所有神經元相連，第 N-1 層神經元的輸出就是第 N 層神經元的輸入。\n",
    "- 每個連接都有一個權值。\n",
    "\n",
    "**神經網絡架構**\n",
    "圖 2-1 是一個神經網絡系統，它由很多層組成。對輸入信息的傳遞和加工處理。\n",
    "![圖2-2神經網絡系統](img/ch2/2.5.1.png)\n",
    "\n",
    "圖 2-1 神經網絡系統"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 各種常見算法圖示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用機器學習中，我們經常會遇見各種算法，圖 2-2 是各種常見算法的圖示。\n",
    "\n",
    "|線性回歸(Linear Regression)|K-平均算法 (k-means clustering)|正規化 (Regularization)|\n",
    "| :----------------------:| :----------------------:| :----------------------:|\n",
    "|![](./img/ch2/2.1/1.jpg)|![](./img/ch2/2.1/2.jpg)|![](./img/ch2/2.1/3.jpg)|\n",
    "\n",
    "|決策樹 (Decision Tree)|貝氏推論 (Bayesian inference)|Kernel-Based Learning Algorithm|\n",
    "| :----------------------:| :----------------------:| :----------------------:|\n",
    "| ![](./img/ch2/2.2.4.png)| ![](./img/ch2/2.1/5.jpg)| ![](./img/ch2/2.1/6.jpg)|\n",
    "\n",
    "|集群分析 (Cluster Analysis)|關聯規則學習 (Association Rule Learning)|神經網絡 (Neural Network)|\n",
    "| :----------------------:| :----------------------:| :-----------------------:|\n",
    "| ![](./img/ch2/2.1/7.jpg)| ![](./img/ch2/2.2.8.png)| ![](./img/ch2/2.2.09.png)|\n",
    "\n",
    "|深度學習 (Deep Learning)|主成分分析 (Principal Component Analysis)|集成學習 (Ensemble Learning)|\n",
    "| :-----------------------:| :-----------------------:| :-----------------------:|\n",
    "| ![](./img/ch2/2.2.10.png)| ![](./img/ch2/2.2.11.png)| ![](./img/ch2/2.2.12.png)|\n",
    "\n",
    "圖 2-2 各種常見算法圖示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Computational Graph 的導數計算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computational Graph 的導數計算是反向傳播，利用 Chain Rule 和隱函式 (Implicit Equation) 求導。\n",
    "\n",
    "假設 $z=f(u, v)$ 在點 $(u, v)$ 處偏導連續，$(u, v)$ 是關於 $t$ 的函數，在 $t$ 點可導，求 $z$ 在 $t$ 點的導數。\n",
    "\n",
    "根據Chain Rule有：\n",
    "$$\n",
    "\\frac {dz}{dt}=\\frac {\\partial z}{\\partial u}\\frac {du}{dt}+\\frac{\\partial z}{\\partial v}\\frac {dv}{dt}\n",
    "$$\n",
    "\n",
    "Example：\n",
    "$$\n",
    "f(x)= x^{2}\n",
    "$$\n",
    "$$\n",
    "g(x)=2x+1\n",
    "$$\n",
    "\n",
    "則：\n",
    "$$\n",
    "{f(g(x))}'=2(g(x))g'(x)=2(2x+1)2=8x+4\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 局部最優解 與 全局最優解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "笑談局部最優和最大化\n",
    "\n",
    ">柏拉圖有一天問老師蘇格拉底什麼是愛情？蘇格拉底叫他到麥田走一次，摘一顆最大的麥穗回來，不許回頭，只可摘一次。柏拉圖空著手出來了，他的理由是，看見不錯的，卻不知道是不是最好的，一次次僥倖，走到盡頭時，才發現還不如前面的，於是放棄。蘇格拉底告訴他：“這就是愛情。”這故事讓我們明白了一個道理，因為生命的一些不確定性，所以可能最優解是很難尋找到的，或者說根本就不存在，我們應該設置一些限定條件，然後在這個範圍內尋找最優解，也就是局部最優解-有所斬獲總比空手而歸強，哪怕這種斬獲只是一次有趣的經歷。\n",
    ">柏拉圖有一天又問什麼是婚姻？蘇格拉底叫他到樹林走一次，選一棵最好的樹做聖誕樹，也是不許回頭，只許選一次。看起來直挺，翠綠，卻有點稀疏的杉樹回來，他的理由是，有了上回的教訓，好不容易看見一棵看似不錯的，又發現時間，體力已經快不夠用了，也不管是不是最好的，就拿回來了。蘇格拉底告訴他：“這就是婚姻。”\n",
    "\n",
    "最佳問題解答一般有局部最優解和最大化最優解：\n",
    "- 局部最優解：在函數值空間的一個有限區域內尋找代替解答(最接近)。<br>\n",
    "- 最優解：是在函數值空間整個區域尋找問題的最佳解答。<br>\n",
    "- 函數局部最小點是它的函數值小於或等於附近點的點，但是有可能大於較遠距離的點。<br>\n",
    "- 全局最小點是那種它的函數值小於或等於所有的可行點。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 大數據與深度學習之間的關係"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先來看大數據，機器學習及數據挖掘三者簡單的定義：\n",
    "\n",
    "**大數據**：通常被定義為「超過常用軟件工具捕獲，管理和處理能力」的數據集。<br>\n",
    "**機器學習**：關心問題是如何整合電腦程序使用經驗自動改進。<br>\n",
    "**數據挖掘**：是從數據中提取特定模式算法的應用，在數據挖掘中，重點在於算法的應用，而不是算法本身。<br>\n",
    "\n",
    "三者之間的關係如下：\n",
    "數據挖掘是一個過程，在此過程中機器學習算法被用來提取數據集中的潛在的潛在模式的工具。\n",
    "\n",
    "大數據與深度學習關係總結如下：\n",
    "- 深度學習是一種模擬大腦的行為。可以從所學習對象的機制以及行為等等很多相關聯的方面進行學習，模仿類型行為以及思維。<br>\n",
    "- 深度學習對於大數據技術開發的每一個階段幫助，無論是數據的分析還是挖掘還是建模，只有深度學習，這些工作才會有可能一一得到實現。<br>\n",
    "- 深度學習轉變了解決問題的思維。很多時候發現問題到解決問題，走一步算一步不再是主要的解決問題的方式。在深度學習的基礎上，要求我們從開始到最後都要依據一個目標，為了需要優化的那個最終目標去進行處理以及將數據放入到數據應用平台上去，這就是 End-to-End。<br>\n",
    "- 在大數據方面的深度學習都是從基礎的角度出發的，深度學習需要一個框架或者一個系統。總而言之，將大數據通過深度分析變為現實，這就是深度學習和大數據的最直接關係。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 機器學習學習方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根據數據類型的不同，每個問題的建模都會有不同的方式來依據不同的學習方式和輸入數據，機器學習主要分為以下學習方式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 監督式學習 (Supervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據：監督學習是使用已知正確答案的示例來訓練網絡。<br>\n",
    "定義：已知數據和其對應的標籤，訓練一個預測模型，將輸入數據映射到標籤的過程。<br>\n",
    "常見應用場景：監督式學習的常見應用場景如 分類問題 (Classification) 和 回歸問題 (Regression)。<br>\n",
    "\n",
    "常見算法：\n",
    "- Support Vector Machine (SVM)<br>\n",
    "- Naive Bayes<br>\n",
    "- Logistic Regression<br>\n",
    "- K-Nearest Neighborhood (KNN)<br>\n",
    "- Decision Tree<br>\n",
    "- Random Forest<br>\n",
    "- AdaBoost<br>\n",
    "- Linear Discriminant Analysis (LDA)\n",
    "\n",
    "深度學習(Deep Learning) 大多也是以監督學習的方式呈現。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 非監督式學習 (Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據：在非監督式學習中，數據並不一定有標示<br>\n",
    "定義：適用於有數據集但無標籤的情況。此學習模型是為了替換找出數據的一些內在結構。<br>\n",
    "常見應用場景：通用的應用場景包括 Association Rule Learning 的學習以及聚類分析 (Cluster Analysis)等。<br>\n",
    "\n",
    "常見算法：\n",
    "- Apriori<br>\n",
    "- K-Means<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 半監督式學習 (Semi-supervised Learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "數據：在此學習方式下，輸入數據部分被標記、部分沒有，這種學習模型可以進行預測。<br>\n",
    "常見應用場景：應用場景包括分類和回歸，算法包括一些針對常用 Supervised Learning 的延伸，通過對已標記數據建模，接此在此基礎上對未標記數據進行預測。<br>\n",
    "\n",
    "常用算法：\n",
    "- 論證推理算法（圖論）<br>\n",
    "- Laplace SVM<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 弱監督式學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特色：弱監督學習可以看做是有多個標記的數據集合，次集合可以是空集，個別元素，或包含多種情況（沒有標記，有一個標記，和有多個標記）的多個數據集的標籤是不可靠的，這裡的不可靠可以是標記不正確，多種標記，標記不充分，局部標記等。已知數據和其一一對應的弱標籤，訓練一個智能算法，將輸入數據映射到一組更強的標籤的過程。標籤的強弱指的是標籤蘊含的信息量的多少，而相對於分割的標籤來說，分類的標籤就是弱標籤。\n",
    "\n",
    "算法演算：重新計算，得到一張包含氣球的圖片，需要重新獲得氣球在圖片中的位置及氣球和背景的分割線，這就是已知的弱標籤學習強標籤的問題。\n",
    "\n",
    "在企業數據應用的場景下，人們最常見的可能是監督式學習和非監督式學習的模型。在圖像識別等領域，由於存在大量的非標識的數據和少量的可標識數據，目前半監督式學習是一個很熱的話題。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5監督學習有哪些步驟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "監督學習是使用已知正確答案的示例來訓練網絡，每組訓練數據有一個明確的標識或結果。想像一下，我們可以訓練一個網絡，讓其從照片庫中（其中包含氣球的照片）識別出氣球的照片。以下就是我們在這個假設場景中所要採取的步驟。\n",
    "\n",
    "**步驟1：數據集的創建和分類**\n",
    "首先，瀏覽你的照片（數據集），確定所有包含氣球的照片，並進行進行標註。然後，將所有照片分為訓練集和驗證集。目標就是在深度網絡中找一個函數，這個函數輸入是任意一張照片，當照片中包含氣球時，輸出1，否則輸出0。\n",
    "\n",
    "**步驟2：數據增強（數據增強）**\n",
    "當原始數據蒐集和標註完畢，一般蒐集的數據並不一定包含目標在各種擾動下的信息。數據的好壞對於機器學習模型的預測能力至關重要，因此一般會進行數據增強。數據來說，數據增強一般包括，圖像旋轉，平移，顏色變換，裁剪，仿射變換等。\n",
    "\n",
    "**步驟3：特徵工程（特徵工程）**\n",
    "常見的手工特徵（手工製作的特徵）有尺度不變特徵變換（Scale-Invariant Feature Transform，SIFT），方向梯度直方圖（Oriented Gradient， HOG）等。由於手工特徵是啟發式的，其算法設計背後的出發點不同，將這些特徵組合在一起的時候有可能會產生衝突，如何將組合特徵的性能發揮出來，使原始數據在特徵空間中在深度學習方法大獲成功之後，人們很大一部分不再關注特徵工程本身。因為，最常用到的捲積神經網絡（卷積神經網絡， CNNs）本身就是一種特徵提取和選擇的引擎。研究者提出的不同的網絡結構，正則化，歸一化方法實際上就是深度學習背景下的特徵工程。\n",
    "\n",
    "**步驟4：建立預測模型和損失**\n",
    "將原始數據映射到特徵空間之後，也就意味著我們得到了比較合理的輸入。然後就是適當的預測模型得到對應的輸入的輸出。而如何保證模型的輸出和輸入標籤的一致性，就需要優化模型預測和標籤之間的損失函數，常見的損失函數（損失函數）有交叉熵，均方差等。通過優化方法不斷迭代，使模型從最初的初始化狀態一步步變化為有預測能力的模型的過程，實際上就是學習的過程。\n",
    "\n",
    "**步驟5：訓練**\n",
    "選擇合適的模型和超參數進行初始化，其中超參數設置支持矢量機中核函數，誤差項懲罰權重等。當模型初始化參數設置好後，將製作好的特徵數據輸入到模型，通過合適的優化方法不斷縮小輸出與標籤之間的差異，當交替過程到了終止條件，就可以得到訓練好的模型。優化方法最常見的就是漸變下降法及其變種，使用梯度下降法的替代是優化目標函數針對模型是可導的。\n",
    "\n",
    "**步驟6：驗證和模型選擇**\n",
    "訓練完訓練集圖片後，需要進行模型測試。利用驗證集來驗證模型是否可以準確地挑選出含有氣球內部的照片。\n",
    "在此過程中，通常會通過調整和模型相關的各種事物（超參數）來重複步驟2和3，其中里面有多少個節點，有多少層，使用怎樣的激活函數和損失函數，如何在反向傳播階段積極有效地訓練權值等等。\n",
    "\n",
    "**步驟7：測試及應用**\n",
    "當有了一個準確的模型，就可以通過模型部署到您的應用程序中。您可以將預測功能發佈為API（應用編程接口，應用程序編程接口）調用，並且您可以從軟件中調用該API，從而進行推理並提供相應的結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
